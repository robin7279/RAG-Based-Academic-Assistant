# RAG-Based-Academic-Assistant
ğŸ“ A Retrieval-Augmented Generation (RAG) based academic assistant that lets you upload PDFs, ask questions, and get smart answers from your documents.
It built with **Streamlit**, **FastAPI**, and **LangGraph**, powered by **local document processing** and conversational memory.

## ğŸš€ Features

- ğŸ’¬ Conversational AI powered by LangGraph
- ğŸ“„ Upload and index PDF academic documents
- ğŸ” Contextual Q&A from uploaded files
- ğŸ“ Attachment-style file upload next to chat input
- ğŸ§  Memory support per conversation thread

## ğŸ› ï¸ Requirements

Make sure you have the following in your `requirements.txt`:


## ğŸ“‚ Folder Structure

ğŸ“ RAG-Academic-Assistant/
â”œâ”€â”€ ğŸ“‚ books/                    # Folder to store academic PDFs
â”œâ”€â”€ ğŸ“‚ vectorstore/              # Saved FAISS vector database
â”œâ”€â”€ ğŸ“‚ .streamlit/               # Streamlit config (optional)
â”œâ”€â”€ ğŸ“„ main.py                   # Entry point (FastAPI + Streamlit UI)
â”œâ”€â”€ ğŸ“„ llm_handler.py            # LLM logic, retrieval, and graph setup
â”œâ”€â”€ ğŸ“„ knowledge_base.py         # PDF loading, splitting, embedding
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ .env                      # Environment variables (e.g., GROQ_API_KEY)
â””â”€â”€ ğŸ“„ README.md                 # Project documentation


## âš™ï¸ Usage

1. **Install dependencies**  
   ```bash
   pip install -r requirements.txt

2. **Run the app**  
   ```bash
   streamlit run main.py
